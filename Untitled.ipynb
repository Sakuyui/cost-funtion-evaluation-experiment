{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "d8fda7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from numpy.random import rand\n",
    "from scipy.sparse import spdiags,linalg,eye\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "6d082737",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_base_path = \"./integrated_reports/\"\n",
    "summary_file_format = \"s-max-atoms-per-core-%d-trail-%d.rpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "730f0c8a-f157-4139-a4dc-f15a0f6dc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_file(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = (f.read())\n",
    "        f.close()\n",
    "    return data\n",
    "\n",
    "def analyze_summary_file(max_atoms_per_core, trails=5):\n",
    "    joules_regex = r'.* ([0-9]+\\.[0-9]+) Joules.*'\n",
    "    seconds_regex = r'.* ([0-9]+\\.[0-9]+) seconds.*'\n",
    "    milliseconds_regex = r'.* ([0-9]+\\.[0-9]+) milliseconds.*'\n",
    "\n",
    "   \n",
    "    analyzed_data = dict({})\n",
    "\n",
    "    def analyze_joules(description):\n",
    "        joules_match = re.match(joules_regex, description)\n",
    "        return {\n",
    "            'joules': (float)(joules_match.group(1))\n",
    "        }\n",
    "    def analyze_time(description):\n",
    "        time_match = re.match(seconds_regex, description)\n",
    "        if time_match != None:\n",
    "            return {\n",
    "                'secs': (float)(time_match.group(1)),\n",
    "            }\n",
    "        else:\n",
    "            time_match = re.match(milliseconds_regex, description)\n",
    "            return {\n",
    "                'm_secs': (float)(time_match.group(1)),\n",
    "            }\n",
    "    def analyze_general_number(description):\n",
    "        joules_match = re.match( r'.* ([0-9]+\\.[0-9]+) .*', description)\n",
    "        return (float)(joules_match.group(1))\n",
    "        \n",
    "    def analyze_joules_and_seconds(description):\n",
    "        joules_item = analyze_joules(description)\n",
    "        time_item = analyze_time(description)\n",
    "        \n",
    "        return joules_item | time_item\n",
    "\n",
    "    analyzed_data['atoms_per_core'] = max_atoms_per_core\n",
    "    analyzed_data['trail_data'] = []\n",
    "\n",
    "    for trail_id in range(trails):\n",
    "        file_path = os.path.join(record_base_path, summary_file_format % (max_atoms_per_core ,trail_id))\n",
    "        data = read_file(file_path)\n",
    "        if data == None:\n",
    "            print(\"warning %s not exist.\" % file_path)\n",
    "            continue\n",
    "        data = data.split(\"\\n\")[3:]\n",
    "\n",
    "        current_trail_record = dict({})\n",
    "        \n",
    "        current_trail_record['trail_id'] = trail_id\n",
    "    \n",
    "        current_trail_record['energy-used-by-chips'] = analyze_joules_and_seconds(data[0])\n",
    "        current_trail_record['energy-used-by-fpgas-entire'] = analyze_joules_and_seconds(data[1])\n",
    "        current_trail_record['energy-used-by-fpgas-runtime-period'] = analyze_joules_and_seconds(data[2])\n",
    "        current_trail_record['energy-used-by-outside-route'] = analyze_joules(data[3])\n",
    "        current_trail_record['energy-used-by-packet-transmissions'] = analyze_joules_and_seconds(data[4])\n",
    "        current_trail_record['energy-used-by-mapping-process'] = analyze_joules_and_seconds(data[5])\n",
    "        current_trail_record['energy-used-by-data-generation'] = analyze_joules_and_seconds(data[6])\n",
    "        current_trail_record['energy-used-by-loading-process'] = analyze_joules_and_seconds(data[7])\n",
    "        current_trail_record['energy-used-by-data-extraction'] = analyze_joules_and_seconds(data[8])\n",
    "        current_trail_record['total-simulation-time'] = analyze_time(data[9])\n",
    "        current_trail_record['total-energy-joules'] = analyze_joules(data[10])\n",
    "        current_trail_record['avg-kwh'] = analyze_general_number(data[12])\n",
    "\n",
    "        analyzed_data['trail_data'].append(current_trail_record)\n",
    "\n",
    "    return analyzed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "124bdd0c-709a-446e-a355-607845e05fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_record(record_count = 1200):\n",
    "    all_record = []\n",
    "    for i in range(record_count):\n",
    "        \n",
    "        all_record.append(analyze_summary_file(i + 1))\n",
    "    return all_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "35e1223c-dd2c-42c7-bdce-c4f628de5438",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = load_all_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1bc6f204-d637-4385-a022-203375b482ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.94421624888918 15.588214115555624 3.7813322175288953\n",
      "1.0 1.0 1.0\n",
      "0.025978646719999998 0.006229602719999998 4.17019317084156\n",
      "79.32257340000001 20.366762200000004 3.8947071027323132\n"
     ]
    }
   ],
   "source": [
    "# calculate max fpga differs (factor)\n",
    "# energy-used-by-chips\n",
    "\n",
    "def calc_observed_item_average(item_name, observation_type, records, observation_times = 5):\n",
    "    d1 = list(map(lambda record: record['trail_data'][-1][item_name][observation_type] / observation_times, records))\n",
    "    print(max(d1), min(d1), max(d1)/ min(d1))\n",
    "    return \n",
    "\n",
    "calc_observed_item_average('energy-used-by-chips', 'joules', records)\n",
    "calc_observed_item_average('energy-used-by-chips', 'secs', records)\n",
    "calc_observed_item_average('energy-used-by-packet-transmissions', 'joules', records)\n",
    "calc_observed_item_average('energy-used-by-packet-transmissions', 'secs', records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "4c823d22-553b-4a72-a714-d409c1bf7597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atoms_per_core': 1,\n",
       " 'trail_data': [{'trail_id': 0,\n",
       "   'energy-used-by-chips': {'joules': 58.91421937777772, 'secs': 1.0},\n",
       "   'energy-used-by-fpgas-entire': {'joules': 265.33269874236,\n",
       "    'secs': 88.659638},\n",
       "   'energy-used-by-fpgas-runtime-period': {'joules': 3.50781, 'secs': 1.0},\n",
       "   'energy-used-by-outside-route': {'joules': 117.0},\n",
       "   'energy-used-by-packet-transmissions': {'joules': 0.02609291759999998,\n",
       "    'secs': 117.867662},\n",
       "   'energy-used-by-mapping-process': {'joules': 3417.3388080000004,\n",
       "    'secs': 29.208024},\n",
       "   'energy-used-by-data-generation': {'joules': 0.0, 'm_secs': 0.0},\n",
       "   'energy-used-by-loading-process': {'joules': 15316.86047382936,\n",
       "    'secs': 75.640556},\n",
       "   'energy-used-by-data-extraction': {'joules': 2637.336228280423,\n",
       "    'secs': 13.019082000000001},\n",
       "   'total-simulation-time': {'m_secs': 117867.662},\n",
       "   'total-energy-joules': {'joules': 21812.808521147523},\n",
       "   'avg-kwh': 0.006059113478096534},\n",
       "  {'trail_id': 1,\n",
       "   'energy-used-by-chips': {'joules': 117.73357759999955, 'secs': 2.0},\n",
       "   'energy-used-by-fpgas-entire': {'joules': 457.10949818892,\n",
       "    'secs': 153.94466300000002},\n",
       "   'energy-used-by-fpgas-runtime-period': {'joules': 7.01562, 'secs': 2.0},\n",
       "   'energy-used-by-outside-route': {'joules': 234.0},\n",
       "   'energy-used-by-packet-transmissions': {'joules': 0.05195608800000002,\n",
       "    'secs': 183.15268700000001},\n",
       "   'energy-used-by-mapping-process': {'joules': 3417.3388080000004,\n",
       "    'secs': 29.208024},\n",
       "   'energy-used-by-data-generation': {'joules': 0.0, 'm_secs': 0.0},\n",
       "   'energy-used-by-loading-process': {'joules': 15316.86047382936,\n",
       "    'secs': 75.640556},\n",
       "   'energy-used-by-data-extraction': {'joules': 4787.392662516899,\n",
       "    'secs': 23.632731000000003},\n",
       "   'total-simulation-time': {'m_secs': 183152.687},\n",
       "   'total-energy-joules': {'joules': 24330.486976223176},\n",
       "   'avg-kwh': 0.006758468604506438},\n",
       "  {'trail_id': 2,\n",
       "   'energy-used-by-chips': {'joules': 176.66090986666592, 'secs': 3.0},\n",
       "   'energy-used-by-fpgas-entire': {'joules': 651.10003794057,\n",
       "    'secs': 224.474948},\n",
       "   'energy-used-by-fpgas-runtime-period': {'joules': 10.523430000000001,\n",
       "    'secs': 3.0},\n",
       "   'energy-used-by-outside-route': {'joules': 351.0},\n",
       "   'energy-used-by-packet-transmissions': {'joules': 0.07791330160000018,\n",
       "    'secs': 253.682972},\n",
       "   'energy-used-by-mapping-process': {'joules': 3417.3388080000004,\n",
       "    'secs': 29.208024},\n",
       "   'energy-used-by-data-generation': {'joules': 0.0, 'm_secs': 0.0},\n",
       "   'energy-used-by-loading-process': {'joules': 15316.86047382936,\n",
       "    'secs': 75.640556},\n",
       "   'energy-used-by-data-extraction': {'joules': 7872.16326030046,\n",
       "    'secs': 38.86055100000001},\n",
       "   'total-simulation-time': {'m_secs': 253682.972},\n",
       "   'total-energy-joules': {'joules': 27785.201403238654},\n",
       "   'avg-kwh': 0.007718111500899626},\n",
       "  {'trail_id': 3,\n",
       "   'energy-used-by-chips': {'joules': 235.83049706666648, 'secs': 4.0},\n",
       "   'energy-used-by-fpgas-entire': {'joules': 854.6449962265799,\n",
       "    'secs': 295.596906},\n",
       "   'energy-used-by-fpgas-runtime-period': {'joules': 14.03124, 'secs': 4.0},\n",
       "   'energy-used-by-outside-route': {'joules': 468.0},\n",
       "   'energy-used-by-packet-transmissions': {'joules': 0.10391013200000043,\n",
       "    'secs': 324.80493},\n",
       "   'energy-used-by-mapping-process': {'joules': 3417.3388080000004,\n",
       "    'secs': 29.208024},\n",
       "   'energy-used-by-data-generation': {'joules': 0.0, 'm_secs': 0.0},\n",
       "   'energy-used-by-loading-process': {'joules': 15316.86047382936,\n",
       "    'secs': 75.640556},\n",
       "   'energy-used-by-data-extraction': {'joules': 10525.027849841594,\n",
       "    'secs': 51.95628800000001},\n",
       "   'total-simulation-time': {'m_secs': 324804.93},\n",
       "   'total-energy-joules': {'joules': 30817.806535096202},\n",
       "   'avg-kwh': 0.008560501815304501},\n",
       "  {'trail_id': 4,\n",
       "   'energy-used-by-chips': {'joules': 294.7210812444459, 'secs': 5.0},\n",
       "   'energy-used-by-fpgas-entire': {'joules': 1061.36282478255,\n",
       "    'secs': 367.404843},\n",
       "   'energy-used-by-fpgas-runtime-period': {'joules': 17.53905, 'secs': 5.0},\n",
       "   'energy-used-by-outside-route': {'joules': 585.0},\n",
       "   'energy-used-by-packet-transmissions': {'joules': 0.1298932336,\n",
       "    'secs': 396.61286700000005},\n",
       "   'energy-used-by-mapping-process': {'joules': 3417.3388080000004,\n",
       "    'secs': 29.208024},\n",
       "   'energy-used-by-data-generation': {'joules': 0.0, 'm_secs': 0.0},\n",
       "   'energy-used-by-loading-process': {'joules': 15316.86047382936,\n",
       "    'secs': 75.640556},\n",
       "   'energy-used-by-data-extraction': {'joules': 13133.622378919195,\n",
       "    'secs': 64.83348800000002},\n",
       "   'total-simulation-time': {'m_secs': 396612.867},\n",
       "   'total-energy-joules': {'joules': 33809.03546000915},\n",
       "   'avg-kwh': 0.009391398738891431}]}"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_summary_file(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "dbbafa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_configuration(fixed_size, neuron_count):\n",
    "    config = []\n",
    "    current_sum = 0\n",
    "    while current_sum < neuron_count:\n",
    "        if current_sum < 1200 and current_sum + fixed_size  > 1200:\n",
    "            config.append(1200 - current_sum)\n",
    "            current_sum += 1200 - current_sum\n",
    "        elif current_sum >= 1200 and current_sum < 1500 and current_sum + fixed_size > 1500:\n",
    "            config.append(1500 - current_sum)\n",
    "            current_sum += 1500 - current_sum\n",
    "        else:\n",
    "            config.append(fixed_size)\n",
    "            current_sum += fixed_size\n",
    "    if sum(config) != neuron_count:\n",
    "        raise ValueError\n",
    "    return config\n",
    "    \n",
    "def cost(config, H, J, samples, p=0.2):\n",
    "    if samples.shape[1] != len(H) or len(J.shape) < 2 or samples.shape[1] != J.shape[0] or samples.shape[1] != J.shape[1]:\n",
    "        raise ValueError\n",
    "    sample_count = samples.shape[0]\n",
    "    neuron_count = samples.shape[1]\n",
    "    cost_sum = 0\n",
    "\n",
    "    loc_map = [0] * neuron_count\n",
    "\n",
    "    pos = 0\n",
    "    core_atoms_count_record = dict({})\n",
    "\n",
    "    for index, slice_length in enumerate(config):\n",
    "        core_atoms_count_record[index] = slice_length\n",
    "        for inner_slice_index in range(slice_length):\n",
    "            loc_map[pos] = index\n",
    "            pos += 1\n",
    "\n",
    "    def no_normalize_p(sample):\n",
    "        # sample_nor = (sample - (-1)) / 2\n",
    "        extra_field_factor = -np.sum(H * sample)\n",
    "        interaction_factor = 0\n",
    "        neuro_count = sample.shape[0]\n",
    "        tmp_2d_mat_for_calculate_interaction_factor = np.zeros((neuro_count, neuro_count))\n",
    "        # tmp_1d_mat_for_calculate_interaction_factor = np.zeros((neuro_count))\n",
    "        for neuron_index in range(sample.shape[0]):\n",
    "            tmp_2d_mat_for_calculate_interaction_factor[neuron_index] = sample[neuron_index] * sample\n",
    "        \n",
    "        p =  np.exp(extra_field_factor + interaction_factor)\n",
    "        \n",
    "        \n",
    "        return p\n",
    "        \n",
    "\n",
    "    def loc(neuro_index):\n",
    "        return loc_map[neuro_index]\n",
    "\n",
    "  \n",
    "    for i in range(sample_count):\n",
    "        p = no_normalize_p(samples[i]) \n",
    "        for j in range(0, neuron_count):\n",
    "            if samples[i][j] == -1:\n",
    "                core_id_global = loc(j)\n",
    "                core_id_inner_chip = core_id_global % 18\n",
    "                chip_id = core_id_global // 18\n",
    "                atoms_inner_chip =  core_atoms_count_record[core_id_global]\n",
    "                c = 10\n",
    "                cost_sum += p * (atoms_inner_chip * p + c * (len(config) - 1))\n",
    "                \n",
    "    return cost_sum / sample_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "58e34af3-28e1-479f-ba3b-8fcc68761edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_configuration(100, 1500)\n",
    "H = np.random.randn((1500))\n",
    "J = np.random.randn((1500 * 1500)).reshape(1500, 1500)\n",
    "samples = np.random.randint(0, 2, size = (100, 1500))\n",
    "samples[samples == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "c2164c10-6b10-4d8a-aac7-e2770c91bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsingModel2D(object):\n",
    "    def __init__(self, neuron_count, J = None, H = None):\n",
    "        self._J = J if J != None else np.zeros((neuron_count, neuron_count))\n",
    "        self._H = H if H != None else np.zeros((neuron_count))\n",
    "        self._neuron_count = neuron_count\n",
    "        self.configuration = np.zeros((neuron_count))\n",
    "    \n",
    "    def set_J(self, J):\n",
    "        self._J = J\n",
    "    def set_H(self, H):\n",
    "        self._H = H\n",
    "    def get_J(self):\n",
    "        return self._J\n",
    "    def get_H(self):\n",
    "        return self._H\n",
    "    def set_J_element(self, i, j, value):\n",
    "        self._J[i, j] = value\n",
    "    def set_H_element(self, i, value):\n",
    "        self._H[i] = value\n",
    "    def get_neuron_count(self):\n",
    "        return self._neuron_count\n",
    "        \n",
    "class IsingModelBasedCostFunctionConfigurationExporter(object):\n",
    "    def __init__(self, base_path, configuration_name) -> None:\n",
    "        self.base_path = base_path\n",
    "        self.configuration_name = configuration_name\n",
    "\n",
    "    def save_ising_model_parameters(self, model: IsingModel2D):\n",
    "        param_H_file_path = os.path.join(self.base_path, \"%s_H.npy\" % self.configuration_name)\n",
    "        param_J_file_path = os.path.join(self.base_path, \"%s_J.npy\" % self.configuration_name)\n",
    "        np.save(param_H_file_path, model.get_H())\n",
    "        np.save(param_J_file_path, model.get_J())\n",
    "\n",
    "    def save_ising_model_configuration_samples(self, samples):\n",
    "        samples_file_path = os.path.join(self.base_path, \"%s_samples.npy\" % self.configuration_name)\n",
    "        np.save(samples_file_path, samples)\n",
    "        \n",
    "    def save_all_preprocessing_data(self, model, samples):\n",
    "        self.save_ising_model_parameters(model)\n",
    "        self.save_ising_model_configuration_samples(samples)\n",
    "\n",
    "\n",
    "def mcmove(model: IsingModel2D,  beta):\n",
    "    '''\n",
    "    Monte Carlo move using Metropolis algorithm \n",
    "    '''\n",
    "    N =  model.get_neuron_count()\n",
    "    for _ in range(1):\n",
    "        random_selected_index = np.random.randint(0, N)\n",
    "        s =  model.configuration[random_selected_index]\n",
    "\n",
    "        # Calculate the energy change if choose to flip the spin.\n",
    "        ### Let us reflect the formula for energy of a configuration:\n",
    "        #### E = -\\sum_{i = 1, j = 1}^{N - 1,N - 1} .5 * J_{ij} * si * sj -\\sum_{i=0}^{N-1} h_i * s_i\n",
    "        dE = 2 * s * (model.get_H()[random_selected_index] + \n",
    "                      0.5 * np.sum(model.get_J()[random_selected_index] * model.configuration))\n",
    "    \n",
    "        # In the condition that the energy change less than 0, flip the spin. (A system has a tendency to \n",
    "        # change to a less energy state, which is more stable.)\n",
    "        if dE < 0:\n",
    "            s = - s\n",
    "            model.configuration[random_selected_index] = s\n",
    "\n",
    "        elif True if dE == np.inf else rand() < dE == np.exp(-dE * beta):\n",
    "            s = - s\n",
    "            model.configuration[random_selected_index] = s\n",
    "        \n",
    "def initilize_ising_model_configuration(model: IsingModel2D):\n",
    "    model.configuration = np.random.choice([-1, 1], (model.get_neuron_count()))\n",
    "    \n",
    "def initilize_ising_model_by_profiled_si_sisj_ensemble_averages(model: IsingModel2D, si, sisj):\n",
    "    model.set_H(si)\n",
    "    model.set_J(sisj)\n",
    "\n",
    "def calculate_si_m_sisj_m_of_ising_model(model: IsingModel2D, \\\n",
    "                                         equilibration_iteration_count = 2**9,\\\n",
    "                                         sampling_count = 2**13):\n",
    "    nt = 1\n",
    "    T = np.linspace(1.53, 3.28, nt); \n",
    "    accumulated_si_observation = np.zeros((neuron_count))\n",
    "    accumulated_sisj_observation = np.zeros((neuron_count, neuron_count))\n",
    "\n",
    "    # for each temperature points\n",
    "    iT = 1.0/T[0]\n",
    "    log_interval = equilibration_iteration_count // 100\n",
    "\n",
    "    for i in range(equilibration_iteration_count):         # equilibrate\n",
    "        print(\"equilibration: %d/%d\" % (i, equilibration_iteration_count))\n",
    "        if i % log_interval == 0:\n",
    "            log(log_file, \"equilibration: %d/%d\" % (i, equilibration_iteration_count))\n",
    "\n",
    "        mcmove(model, iT)           # Monte Carlo moves\n",
    "\n",
    "    print(\"Finish Equilibration\")\n",
    "    log(log_file, \"Finish Equilibration\")\n",
    "    log_interval = sampling_count // 100\n",
    "    for i in range(sampling_count):\n",
    "        print(\"sampling: %d/%d\" % (i, sampling_count))\n",
    "        if i % log_interval == 0:\n",
    "            log(log_file, \"sampling: %d/%d\" % (i, sampling_count))\n",
    "\n",
    "        mcmove(model, iT)      \n",
    "        accumulated_si_observation += model.configuration    \n",
    "        tiled_matrix = np.tile(model.configuration, neuron_count).reshape((neuron_count, neuron_count))\n",
    "        accumulated_sisj_observation = ((tiled_matrix) + tiled_matrix.T) // 2\n",
    "        del tiled_matrix\n",
    "        \n",
    "    \n",
    "    si = accumulated_si_observation / (sampling_count)\n",
    "    sisj = accumulated_sisj_observation / (sampling_count)\n",
    "    return si, sisj \n",
    "\n",
    "def generate_configuration_samples(model, sample_count = 1e4, equilibration_iteration_count = 1e8):\n",
    "    # for each temperature points\n",
    "    configuration_samples = np.zeros((sample_count, neuron_count))\n",
    "    iT=1.0;    \n",
    "    for i in range(equilibration_iteration_count):         # equilibrate\n",
    "        mcmove(model, iT)           # Monte Carlo moves\n",
    "\n",
    "    for i in range(sample_count):\n",
    "        print(\"generate %d-th configuration sample\" % (i + 1))\n",
    "        sampled_configuration = mcmove(model, iT)\n",
    "        configuration_samples[i] = sampled_configuration\n",
    "    return configuration_samples\n",
    "\n",
    "def log(logfile, append_content):\n",
    "\tlogfile.write(\"%s\\n\" % append_content)\n",
    "\tlogfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "5a600253-8c0f-4537-930b-54917fce607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of data source configuration\n",
    "base_file_path = os.path.join(\"./\")\n",
    "population_names = [\"neo_exe_cells\", \"neo_inh_cells\"]\n",
    "dt_now = datetime.datetime.now()\n",
    "time_now_string_description = dt_now.strftime('%Y-%m-%d-%H-%M-%S')\n",
    "log_file_name = \"%s.log\" % time_now_string_description\n",
    "log_file = open(log_file_name, 'w')\n",
    "\n",
    "spikes_record_dfs = []\n",
    "for population_name in population_names:\n",
    "    packet_record_file_name = \"packets_%s\" % population_name\n",
    "    v_record_file_name = \"v_%s\" % population_name\n",
    "    spikes_record_file_name = \"spikes_%s\" % population_name\n",
    "    \n",
    "    packet_record_file_path = os.path.join(base_file_path, packet_record_file_name + \".csv\")\n",
    "    v_record_file_path = os.path.join(base_file_path, v_record_file_name + \".csv\")\n",
    "    spikes_record_file_name = os.path.join(base_file_path, spikes_record_file_name + \".csv\")\n",
    "    \n",
    "    # Read Records\n",
    "    packet_record_df = pd.read_csv(packet_record_file_path) # Columns = slice_id?, rows = time_step\n",
    "    v_record_df = pd.read_csv(v_record_file_path, header=None) # Columns = neuro_index, rows = time_step\n",
    "    spikes_record_df = pd.read_csv(spikes_record_file_name, names=[\"neurons\", \"spikes\"])\n",
    "\n",
    "    spikes_record_dfs.append(spikes_record_df)\n",
    "    time_steps = v_record_df.shape[0]\n",
    "    neuron_count = v_record_df.shape[1]\n",
    "    if v_record_df.shape[0] != packet_record_df.shape[0]:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "# merge\n",
    "neuron_count = 0\n",
    "for spikes_record_df_tmp in spikes_record_dfs:\n",
    "    current_df_neuron_count = max(spikes_record_df_tmp['neurons']) + 1\n",
    "    spikes_record_df_tmp['neurons'] += neuron_count\n",
    "    neuron_count += (int)(current_df_neuron_count)\n",
    "\n",
    "spikes_record_df = pd.concat(spikes_record_dfs, axis = 0)\n",
    "\n",
    "average_each_site_spikes_amount_in_simulation = [(neuron_index,df.size/time_steps) for neuron_index, df in list(spikes_record_df.groupby('neurons'))]\n",
    "\n",
    "# calculate <s_i>\n",
    "ensemble_avgerage_neuron_activation = np.zeros((neuron_count))\n",
    "for (neuron_id, activation_ratio) in average_each_site_spikes_amount_in_simulation:\n",
    "    ensemble_avgerage_neuron_activation[(int)(neuron_id)] = activation_ratio\n",
    "    \n",
    "# calculate <s_is_j>\n",
    "ensemble_avgerage_joint_activation = np.zeros((neuron_count, neuron_count))\n",
    "for i in range(time_steps):\n",
    "    i_time_step_spikes = np.array(spikes_record_df[spikes_record_df.spikes == i].neurons).astype(int)\n",
    "    for j in range(0, len(i_time_step_spikes)):\n",
    "        for k in range(j + 1, len(i_time_step_spikes)):\n",
    "            ensemble_avgerage_joint_activation[i_time_step_spikes[j], i_time_step_spikes[k]] += 1#  joint_activation[i_time_step_spikes[j][0], i_time_step_spikes[k][0]] + 1\n",
    "ensemble_avgerage_joint_activation /= time_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "791775ce-57aa-4f8b-8d56-e6be59ab8f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_avgerage_joint_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a43c7-75bf-47e3-a565-d1e35df19279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "f76d16cd-be7a-450e-8d91-4f765bfddb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1200/1200 [34:02<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "costs = []\n",
    "H = ensemble_avgerage_neuron_activation\n",
    "J = ensemble_avgerage_joint_activation\n",
    "for fixed_size in tqdm.tqdm(range(1200)):\n",
    "    c = cost(create_configuration(fixed_size + 1, 1500), H, J, samples)\n",
    "    costs.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "8d3f2b48-d0d3-49c0-acb4-68182c0e03a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micro\\AppData\\Local\\Temp\\ipykernel_2372\\4253095907.py:1: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  from scipy.stats.stats import pearsonr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.4437623840468995, pvalue=4.601477858686915e-59)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "pearsonr(d1, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5aa86-d3be-48f8-b862-b8024b27ef24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc480d6-86a1-4e52-afe9-97affa5e215d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
